{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKCaVn_7zekV",
        "outputId": "c357c019-c748-4311-fb2b-2e528c8f6dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/663.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/663.2 kB\u001b[0m \u001b[31m728.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m655.4/663.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.2/663.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW6Hsfn6zxhc"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "from IPython.display import display, Image\n",
        "from IPython import display\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "display.clear_output()\n",
        "!yolo mode=checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB3-Mlwfzywz"
      },
      "outputs": [],
      "source": [
        "!yolo settings datasets_dir=/content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrUpYeb11cxT"
      },
      "outputs": [],
      "source": [
        "!pip install -U torch sahi yolov8 ultralytics numpy opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GapU3UXd1ePW"
      },
      "outputs": [],
      "source": [
        "from sahi import AutoDetectionModel\n",
        "from sahi.utils.cv import read_image\n",
        "from sahi.utils.file import download_from_url\n",
        "from sahi.predict import get_prediction, get_sliced_prediction, predict\n",
        "from sahi.prediction import visualize_object_predictions\n",
        "from IPython.display import Image\n",
        "from numpy import asarray\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "601OqAmBp8hv",
        "outputId": "2c6db40d-95c8-42ee-e448-c38f4e9e34a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/AI/R-CNN_proj/innopolis-high-voltage-challenge_1.zip -d my_data"
      ],
      "metadata": {
        "id": "aBl5IgJhzFDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sahi import AutoDetectionModel\n",
        "from sahi.predict import get_sliced_prediction\n",
        "def get_predictions(directory_path, save_path) -> list:\n",
        "    model_path = f'/content/drive/MyDrive/AI/R-CNN_proj/Danila/best700.pt'\n",
        "\n",
        "    detection_model = AutoDetectionModel.from_pretrained(\n",
        "        model_type='yolov8',\n",
        "        model_path=model_path,\n",
        "        confidence_threshold=0.35,\n",
        "        device='cuda:0'\n",
        "    )\n",
        "\n",
        "    res = []\n",
        "    files_and_folders = os.listdir(directory_path)\n",
        "    jpg_files = [file for file in files_and_folders if file.lower().endswith('.jpg')]\n",
        "\n",
        "    for item in jpg_files:\n",
        "        s = f'{directory_path}/{item}'\n",
        "        result = get_sliced_prediction(s,\n",
        "                                       detection_model,\n",
        "                                       slice_height=350,\n",
        "                                       slice_width=350,\n",
        "                                       overlap_height_ratio=0.55,\n",
        "                                       overlap_width_ratio=0.55,\n",
        "                                       )\n",
        "\n",
        "        result.export_visuals(save_path, file_name=item)\n",
        "\n",
        "        size = [result.image_width, result.image_height]\n",
        "        list_with_coordinates = result.object_prediction_list\n",
        "        if len(list_with_coordinates) > 0:\n",
        "            for k, i in enumerate(list_with_coordinates):\n",
        "                bbox = i.bbox\n",
        "                x, y, w, h = bbox.to_xywh()\n",
        "                zz = [x / size[0], y / size[1], w / size[0], h / size[1]]\n",
        "                zz[0] = zz[0] + zz[2] / 2\n",
        "                zz[1] = zz[1] + zz[3] / 2\n",
        "                zz.append(i.score.value)\n",
        "                zz.append(item[:-4] + '_' + str(k + 1))\n",
        "                res.append(zz)\n",
        "        else:\n",
        "            res.append([0, 0, 0, 0, 0, item])\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "YDRx8kNru4OY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = '/content/my_data_d'\n",
        "save_path = '/content/sample_data_d'\n",
        "res = get_predictions(directory_path, save_path)"
      ],
      "metadata": {
        "id": "in3i0w41xlUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "P-qkCVGB1zrd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_csv(res: list, save_path: str):\n",
        "    save_path = '/content/sample_data_d'\n",
        "    d = {}\n",
        "    for i in res:\n",
        "        x, y, w, h, prob, name = i\n",
        "        name = name[:-2]\n",
        "        if name not in d:\n",
        "            d[name] = [[x, y, w, h, prob]]\n",
        "        else:\n",
        "            d[name].append([x, y, w, h, prob])\n",
        "\n",
        "    bit = []\n",
        "    for k, v in d.items():\n",
        "        sub = [k]\n",
        "        nex = []\n",
        "        prob = []\n",
        "        for i in v:\n",
        "            if i[0] == 0 and i[1] == 0 and i[2] == 0 and i[3] == 0:\n",
        "                nex.append(0)\n",
        "            else:\n",
        "                nex.append([i[0], i[1], i[2], i[3]])\n",
        "            prob.append(1 if i[4] > 0 else 0)  # i[4]\n",
        "        sub.append(nex)\n",
        "        sub.append(prob)\n",
        "        bit.append(sub)\n",
        "\n",
        "    rs = list(zip(*bit))\n",
        "    percentile_list = pd.DataFrame(\n",
        "        {'file_name': rs[0],\n",
        "         'rbbox': rs[1],\n",
        "         'probability': rs[2],\n",
        "         })\n",
        "\n",
        "    percentile_list.to_csv(save_path+\"/result.csv\", index=False)"
      ],
      "metadata": {
        "id": "d4Y6s9reu77o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_to_csv(res, '/content/sample_data_d')"
      ],
      "metadata": {
        "id": "NV7WiX2C1m3v"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ncbzy2iJpjwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QIqp2wBBpjzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNXq9wxgpj1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = f'/content/drive/MyDrive/AI/R-CNN_proj/Danila/best700.pt'\n",
        "\n",
        "detection_model = AutoDetectionModel.from_pretrained(\n",
        "        model_type='yolov8',\n",
        "        model_path=model_path,\n",
        "        confidence_threshold=0.35,\n",
        "        device='cuda:0'\n",
        ")"
      ],
      "metadata": {
        "id": "6hFu2Isdy1sS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = []\n",
        "directory_path = '/content/my_data'\n",
        "files_and_folders = os.listdir(directory_path)\n",
        "jpg_files = [file for file in files_and_folders if file.lower().endswith('.jpg')]\n",
        "print(jpg_files)\n",
        "save_path = '/content/sample_data_2'\n",
        "for item in jpg_files:\n",
        "    s = f'{directory_path}/{item}'\n",
        "    result = get_sliced_prediction(s,\n",
        "                                   detection_model,\n",
        "                                    slice_height=500,\n",
        "                                    slice_width=500,\n",
        "                                    overlap_height_ratio=0.55,\n",
        "                                    overlap_width_ratio=0.55,\n",
        "                                    )\n",
        "\n",
        "    result.export_visuals(save_path, file_name=item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "N40oTMZ-y_Df",
        "outputId": "57c0a6b2-5059-4a64-e7cc-197d1f23ca47"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DJI_0038.JPG', 'DJI_0113.JPG', 'DJI_0114.JPG', 'DJI_0120.JPG', 'DJI_0097.JPG', 'DJI_0119.JPG', 'DJI_0111.JPG', 'DJI_0063.JPG', 'DJI_0108.JPG', 'DJI_0059.JPG', 'DJI_0058.JPG', 'DJI_0044.JPG', 'DJI_0095.JPG', 'DJI_0069.JPG', 'DJI_0107.JPG', 'DJI_0116.JPG', 'DJI_0121.JPG', 'DJI_0098.JPG', 'DJI_0105.JPG', 'DJI_0103.JPG', 'DJI_0110.JPG', 'DJI_0096.JPG', 'DJI_0049.JPG', 'DJI_0050.JPG', 'DJI_0094.JPG', 'DJI_0056.JPG', 'DJI_0117.JPG', 'DJI_0081.JPG', 'DJI_0039.JPG', 'DJI_0115.JPG']\n",
            "Performing prediction on 153 number of slices.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3c84cdcc52ed>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjpg_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{directory_path}/{item}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     result = get_sliced_prediction(s,\n\u001b[0m\u001b[1;32m     10\u001b[0m                                    \u001b[0mdetection_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                     \u001b[0mslice_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sahi/predict.py\u001b[0m in \u001b[0;36mget_sliced_prediction\u001b[0;34m(image, detection_model, slice_height, slice_width, overlap_height_ratio, overlap_width_ratio, perform_standard_pred, postprocess_type, postprocess_match_metric, postprocess_match_threshold, postprocess_class_agnostic, verbose, merge_buffer_length, auto_slice_resolution)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mshift_amount_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_image_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarting_pixels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_ind\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_batch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# perform batch prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         prediction_result = get_prediction(\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mdetection_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sahi/predict.py\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(image, detection_model, shift_amount, full_shape, postprocess, verbose)\u001b[0m\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     return PredictionResult(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_prediction_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_prediction_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdurations_in_seconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdurations_in_seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sahi/prediction.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_prediction_list, image, durations_in_seconds)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mdurations_in_seconds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     ):\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image_as_pil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_prediction_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mObjectPrediction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_prediction_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sahi/utils/cv.py\u001b[0m in \u001b[0;36mread_image_as_pil\u001b[0;34m(image, exif_fix)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# image in CHW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mimage_pil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"read image with 'pillow' using 'Image.open()'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tobytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3099\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3101\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sYJhMJvEu5sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = [result.image_width, result.image_height]\n",
        "        list_with_coordinates = result.object_prediction_list\n",
        "        if len(list_with_coordinates) > 0:\n",
        "            for k, i in enumerate(list_with_coordinates):\n",
        "                bbox = i.bbox\n",
        "                x, y, w, h = bbox.to_xywh()\n",
        "                zz = [x / size[0], y / size[1], w / size[0], h / size[1]]\n",
        "                zz[0] = zz[0] + zz[2] / 2\n",
        "                zz[1] = zz[1] + zz[3] / 2\n",
        "                zz.append(i.score.value)\n",
        "                zz.append(item[:-4] + '_' + str(k + 1))\n",
        "                res.append(zz)\n",
        "        else:\n",
        "            res.append([0, 0, 0, 0, 0, item])"
      ],
      "metadata": {
        "id": "tpmsmjYUzR4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBrg_T71IqCu"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/drive/MyDrive/AI/R-CNN_proj/Danila/best700.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhSNF5fgDrVX"
      },
      "outputs": [],
      "source": [
        "yolov8_model_path = file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vClcxoCKztvO"
      },
      "outputs": [],
      "source": [
        "detection_model = AutoDetectionModel.from_pretrained(\n",
        "    model_type='yolov8',\n",
        "    model_path=yolov8_model_path,\n",
        "    confidence_threshold=0.0,\n",
        "    device='cuda:0'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiOwnMVJIyKk"
      },
      "source": [
        "Просматриваем разметку на картинках"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/AI/RCNN-1/Danila/innopolis-high-voltage-challenge.zip -d test_data"
      ],
      "metadata": {
        "id": "piSaetJ0wtGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5843eef0-7908-4bce-f02d-41c0facbef13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/AI/RCNN-1/Danila/innopolis-high-voltage-challenge.zip, /content/drive/MyDrive/AI/RCNN-1/Danila/innopolis-high-voltage-challenge.zip.zip or /content/drive/MyDrive/AI/RCNN-1/Danila/innopolis-high-voltage-challenge.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "s = f'/content/drive/MyDrive/AI/R-CNN_proj/Danila/DJI_20231010100534_0333_Zenmuse-L1-mission.JPG'\n",
        "result = get_sliced_prediction(s,\n",
        "                        detection_model,\n",
        "                        slice_height=500,\n",
        "                        slice_width=500,\n",
        "                        overlap_height_ratio=0.8,\n",
        "                        overlap_width_ratio=0.8,\n",
        "                        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Em1cJsq36WJ",
        "outputId": "e3a4afb3-a75e-479b-c06e-566baa776442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing prediction on 1683 number of slices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.export_visuals(f'demo_data2/', file_name='last_step')"
      ],
      "metadata": {
        "id": "DCBhpjZW4UI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -av \"/content/demo_data2\" \"/content/drive/MyDrive/AI\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLkybJYG4f-R",
        "outputId": "96c6ec5f-35e4-4741-f965-30aa970ebc6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/demo_data2/last_step.png' -> '/content/drive/MyDrive/AI/demo_data2/last_step.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4asOGbbrI4oK"
      },
      "outputs": [],
      "source": [
        "directory_path = '/content/test_data'\n",
        "# Получаем список всех файлов и папок в директории\n",
        "res = []\n",
        "files_and_folders = os.listdir(directory_path)\n",
        "jpg_files = [file for file in files_and_folders if file.lower().endswith('.jpg')]\n",
        "print(jpg_files)\n",
        "for item in jpg_files:\n",
        "    s = f'{directory_path}/{item}'\n",
        "    result = get_sliced_prediction(s,\n",
        "                        detection_model,\n",
        "                        slice_height=500,\n",
        "                        slice_width=500,\n",
        "                        overlap_height_ratio=0.55,\n",
        "                        overlap_width_ratio=0.55,\n",
        "                        )\n",
        "    result.export_visuals(f'demo_data2/', file_name=item)\n",
        "\n",
        "    # img = cv2.imread(f'/content/demo_data/{item}/prediction_visual.png')\n",
        "    #cv2_imshow(img)\n",
        "\n",
        "%cp -av \"/content/demo_data2\" \"/content/drive/MyDrive/AI\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uPxj73GYCGv"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqNch-PddPCb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tqdm\n",
        "\n",
        "directory_path = '/content/test_data'\n",
        "# Получаем список всех файлов и папок в директории\n",
        "res = []\n",
        "files_and_folders = os.listdir(directory_path)\n",
        "jpg_files = [file for file in files_and_folders if file.lower().endswith('.jpg')]\n",
        "\n",
        "for item in jpg_files:\n",
        "    s = f'{directory_path}/{item}'\n",
        "    result = get_sliced_prediction(s,\n",
        "                        detection_model,\n",
        "                        slice_height=500,\n",
        "                        slice_width=500,\n",
        "                        overlap_height_ratio=0.55,\n",
        "                        overlap_width_ratio=0.55,\n",
        "                        )\n",
        "\n",
        "    size = [result.image_width, result.image_height]\n",
        "    list_with_coordinates = result.object_prediction_list\n",
        "    for k, i in enumerate(list_with_coordinates):\n",
        "       bbox = i.bbox\n",
        "       x, y, w, h = bbox.to_xywh()\n",
        "       zz = [x/size[0], y/size[1], w/size[0], h/size[1]]\n",
        "       zz[0] = zz[0] + zz[2]/2\n",
        "       zz[1] = zz[1] + zz[3]/2\n",
        "       zz.append(i.score.value)\n",
        "       zz.append(item[:-4] +'_'+ str(k+1))\n",
        "       res.append(zz)\n",
        "       print(bbox)\n",
        "print(res)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt03XSzaDhCP"
      },
      "outputs": [],
      "source": [
        "d = {}\n",
        "for i in res:\n",
        "  x, y, w, h, prob, name = i\n",
        "  name = name[:-2]\n",
        "  if name not in d:\n",
        "    d[name] = [[x, y, w, h, prob]]\n",
        "  else:\n",
        "    d[name].append([x, y, w, h, prob])\n",
        "\n",
        "bit = []\n",
        "for k, v in d.items():\n",
        "  sub = [k]\n",
        "  nex = []\n",
        "  prob = []\n",
        "  for i in v:\n",
        "    nex.append([i[0], i[1],i[2],i[3]])\n",
        "    prob.append(1) #i[4]\n",
        "  sub.append(nex)\n",
        "  sub.append(prob)\n",
        "  bit.append(sub)\n",
        "\n",
        "import pandas as pd\n",
        "rs = list(zip(*bit))\n",
        "percentile_list = pd.DataFrame(\n",
        "    {'file_name': rs[0],\n",
        "     'rbbox': rs[1],\n",
        "     'probability': rs[2],\n",
        "    })\n",
        "df = pd.read_csv('/content/example_submission_final.csv')\n",
        "df = df.drop([i for i in df.columns if i != 'file_name'], axis=1)\n",
        "commit = df.merge(percentile_list, how='left').fillna(0)\n",
        "commit.to_csv('first.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}