{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0cb3e3e49e694662af1d037f9febbf74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26972ec6337f4969a3f9eba226876fb9",
              "IPY_MODEL_ac8a14586cd44099aac22b893b424de7",
              "IPY_MODEL_15153f7f238346faacabe5272fd6b3b0"
            ],
            "layout": "IPY_MODEL_e4d0f8f2a0794fdd829787dffb2a46de"
          }
        },
        "26972ec6337f4969a3f9eba226876fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a622b680a6f343b4901fe9569d0d4962",
            "placeholder": "​",
            "style": "IPY_MODEL_ae8f53eb10744cb3a3834bf94b5a4b13",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "ac8a14586cd44099aac22b893b424de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14954db1d4f44035b163f2b6b093d2ad",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08d96f574a734a14846167b61f8ae64e",
            "value": 548118077
          }
        },
        "15153f7f238346faacabe5272fd6b3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_918481a37a264d0b8bb2f84cb73cb7f4",
            "placeholder": "​",
            "style": "IPY_MODEL_b7c7821e421147159342d45ef516d543",
            "value": " 548M/548M [00:05&lt;00:00, 155MB/s]"
          }
        },
        "e4d0f8f2a0794fdd829787dffb2a46de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a622b680a6f343b4901fe9569d0d4962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae8f53eb10744cb3a3834bf94b5a4b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14954db1d4f44035b163f2b6b093d2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d96f574a734a14846167b61f8ae64e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "918481a37a264d0b8bb2f84cb73cb7f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7c7821e421147159342d45ef516d543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXQpzoe50TIG"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, pipeline\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## use pretrained from hf"
      ],
      "metadata": {
        "id": "Dso4S2WAHsw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-multilingual-cased')\n",
        "model = AutoModel.from_pretrained('google-bert/bert-base-multilingual-cased')"
      ],
      "metadata": {
        "id": "uW_UGZzh1-NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_text = 'hello, it was so crazy to see you here'\n",
        "inp_text_tokenized = tokenizer(inp_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "inp_text_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbnLyQR02IKk",
        "outputId": "9d46106d-8cc3-40c1-adb1-c32d58cf14e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101, 61694, 10133,   117, 10271, 10134, 10380,   171, 29948, 10157,\n",
              "         10114, 12888, 13028, 19353,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKQLKHcS2A4u",
        "outputId": "f8f1b3f6-b8e7-4896-ad38-475c89879b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(inp_text_tokenized['input_ids'])['pooler_output']"
      ],
      "metadata": {
        "id": "p-F4UTe533NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tokenizer(inp_text)"
      ],
      "metadata": {
        "id": "c8yWyN1e73-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS-2JOuZ9j4f",
        "outputId": "429a2114-a988-43ce-bf14-9faf37cb8040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 61694, 10133, 117, 10271, 10134, 10380, 171, 29948, 10157, 10114, 12888, 13028, 19353, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyBert(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-multilingual-cased')\n",
        "    self.model = AutoModel.from_pretrained('google-bert/bert-base-multilingual-cased')\n",
        "    self.out = nn.Linear(768, 2) # good or bad (sentiment-analysis), just toy example\n",
        "\n",
        "  def forward(self, inp):\n",
        "    tokenized_text = self.tokenizer(inp, return_tensors='pt', padding=True, truncation=True)\n",
        "    out = self.out(self.model(tokenized_text['input_ids'])[\"pooler_output\"])\n",
        "    return out"
      ],
      "metadata": {
        "id": "bNlve6EM0Tke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mybert = MyBert()\n",
        "optimizer = torch.optim.AdamW(mybert.parameters())\n",
        "\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "vWchwfVV0eeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_text = 'hello, it was so crazy to see you here'"
      ],
      "metadata": {
        "id": "Hqy9fH1F6cD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in trange(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  logits = mybert(inp_text)\n",
        "  loss = torch.nn.functional.cross_entropy(logits, torch.tensor([1])) # let's suppose input text is positive (1)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgXkr29s0egs",
        "outputId": "7700f2f6-75b4-495c-8637-ef6ef2a29fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:02<00:25,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7674217224121094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:04<00:18,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10227975994348526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:07<00:18,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001128394273109734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:09<00:14,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.531158240046352e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:11<00:11,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5258672647178173e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:13<00:08,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.768360213347478e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:15<00:06,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7881377516459906e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:17<00:04,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.344646857949556e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:20<00:02,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.768370445162873e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:22<00:00,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.576278118089249e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9fDhKHlO0ejP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## my own transformer"
      ],
      "metadata": {
        "id": "FmvPu1KIHpzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# СУПЕР ВАЖНО НЕ МЕНЯТЬ НИГДЕ НАЗВАНИЯ В САМОМ ТРАНСФОРМЕРЕ И В ДРУГИХ КЛАССАХ НУЖНЫХ ДЛЯ НЕГО\n",
        "# ДЕЛО В ТОМ, ЧТО В GPT2 ТАКИЕ НАЗВАНИЯ СЛОЕВ, А МЫ ЗАГРУЖАЕМ ВЕСА ДЛЯ НЕЕ"
      ],
      "metadata": {
        "id": "140rqOLId79K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "state_dict = torch.load(hf_hub_download(\"gpt2\", filename=\"pytorch_model.bin\"))\n",
        "for key, value in tuple(state_dict.items()):\n",
        "    if key.startswith('h.') and key.endswith('.weight') and value.ndim == 2:\n",
        "        value.transpose_(1, 0)  # <-- for compatibility with modern PyTorch modules\n",
        "    if key.startswith('h.') and key.endswith('.attn.bias') and value.ndim == 4:\n",
        "        state_dict.pop(key)  # <-- triangular binar masks, not needed in this code\n",
        "\n",
        "print('Weights:', repr(sorted(state_dict.keys()))[:320], '...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "0cb3e3e49e694662af1d037f9febbf74",
            "26972ec6337f4969a3f9eba226876fb9",
            "ac8a14586cd44099aac22b893b424de7",
            "15153f7f238346faacabe5272fd6b3b0",
            "e4d0f8f2a0794fdd829787dffb2a46de",
            "a622b680a6f343b4901fe9569d0d4962",
            "ae8f53eb10744cb3a3834bf94b5a4b13",
            "14954db1d4f44035b163f2b6b093d2ad",
            "08d96f574a734a14846167b61f8ae64e",
            "918481a37a264d0b8bb2f84cb73cb7f4",
            "b7c7821e421147159342d45ef516d543"
          ]
        },
        "id": "cWcKMc8g0eln",
        "outputId": "4cbe605f-2e8e-4813-c255-3fd308386e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cb3e3e49e694662af1d037f9febbf74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: ['h.0.attn.c_attn.bias', 'h.0.attn.c_attn.weight', 'h.0.attn.c_proj.bias', 'h.0.attn.c_proj.weight', 'h.0.ln_1.bias', 'h.0.ln_1.weight', 'h.0.ln_2.bias', 'h.0.ln_2.weight', 'h.0.mlp.c_fc.bias', 'h.0.mlp.c_fc.weight', 'h.0.mlp.c_proj.bias', 'h.0.mlp.c_proj.weight', 'h.1.attn.c_attn.bias', 'h.1.attn.c_attn.weight', 'h.1. ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GeLUThatWasUsedInGPT2(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * x ** 3)))\n",
        "\n",
        "class FullyConnected(nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.c_fc = nn.Linear(dim, 4  * dim)\n",
        "        self.gelu = GeLUThatWasUsedInGPT2()\n",
        "        self.c_proj = nn.Linear(4 * dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape = [batch_size, seq_length, dim]\n",
        "        out = self.gelu(self.c_fc(x))\n",
        "        out = self.c_proj(out)\n",
        "        return out # [batch_size, sequence_length, dim]"
      ],
      "metadata": {
        "id": "EQxB86G80eoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = FullyConnected(dim=768)\n",
        "mlp.load_state_dict({'c_fc.weight': state_dict['h.0.mlp.c_fc.weight'],\n",
        "                     'c_fc.bias': state_dict['h.0.mlp.c_fc.bias'],\n",
        "                     'c_proj.weight': state_dict['h.0.mlp.c_proj.weight'],\n",
        "                     'c_proj.bias': state_dict['h.0.mlp.c_proj.bias']})\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "x = torch.randn(1, 2, 768)  # [batch_size, sequence_length, dim]\n",
        "checksum = torch.sum(mlp(x) * x)\n",
        "assert abs(checksum.item() - 1282.3315) < 0.1, \"layer outputs do not match reference\"\n",
        "assert torch.allclose(mlp(x[:, (1, 0), :])[:, (1, 0), :], mlp(x)), \"mlp must be permutation-invariant\"\n",
        "print(\"Seems legit!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ni7PWtH0eqz",
        "outputId": "e131b87e-1f26-4573-a1ed-724e053b9c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems legit!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Scaled_dot_product_attention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "  def forward(self, q, k, v, mask=None):\n",
        "    # [batch_size, head, length, dim_tensor]\n",
        "    k_t = k.transpose(2, 3)\n",
        "    score = (q @ k_t) / math.sqrt(v.shape[-1])\n",
        "\n",
        "    if mask is not None:\n",
        "      score = score.masked_fill(mask == 0, -10000)\n",
        "      # значения, где маска == 0 заменятся на -10000, что в софтмаксе даст почти ничего\n",
        "\n",
        "    score = self.softmax(score)\n",
        "    v = score @ v\n",
        "\n",
        "    return v, score"
      ],
      "metadata": {
        "id": "1qvWdeaI5NL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedSelfAttention(nn.Module):\n",
        "    def __init__(self, dim: int, num_heads: int):\n",
        "        super().__init__()\n",
        "        self.c_attn = nn.Linear(dim, dim * 3)  # query + key + value, combined\n",
        "        self.c_proj = nn.Linear(dim, dim)  # output projection\n",
        "        self.dim, self.num_heads = dim, num_heads\n",
        "        self.head_size = dim // num_heads\n",
        "        self.attn = Scaled_dot_product_attention()\n",
        "\n",
        "    def forward(self, x):\n",
        "        q, k, v = self.c_attn(x).split(dim=-1, split_size=self.dim)\n",
        "        assert q.shape == k.shape == v.shape == x.shape, \"q, k and v must have the same shape as x\"\n",
        "\n",
        "        q, k, v = self.split(q), self.split(k), self.split(v)\n",
        "        # q=, k=, v = [batch_size, head, length, dim_tensor]\n",
        "\n",
        "        out, score = self.attn(q, k, v, mask=self.get_mask(q)) # [batch_size, head, length, dim_tensor]\n",
        "\n",
        "        out = self.concat(out)\n",
        "        out = self.c_proj(out) # [batch_size, length, dim_model]\n",
        "\n",
        "        return out\n",
        "\n",
        "    def split(self, tensor):\n",
        "        \"\"\"\n",
        "        split tensor by number of head\n",
        "\n",
        "        :param tensor: [batch_size, length, dim_model]\n",
        "        :return: [batch_size, head, length, dim_tensor]\n",
        "        \"\"\"\n",
        "        batch_size, length, dim_model = tensor.size()\n",
        "\n",
        "        dim_tensor = dim_model // self.num_heads\n",
        "        tensor = tensor.view(batch_size, length, self.num_heads, dim_tensor).transpose(1, 2)\n",
        "\n",
        "        return tensor\n",
        "\n",
        "    def concat(self, tensor):\n",
        "        \"\"\"\n",
        "        inverse function of self.split(tensor : torch.Tensor)\n",
        "\n",
        "        :param tensor: [batch_size, head, length, dim_tensor]\n",
        "        :return: [batch_size, length, dim_model]\n",
        "        \"\"\"\n",
        "        batch_size, head, length, dim_tensor = tensor.size()\n",
        "        dim_model = head * dim_tensor\n",
        "\n",
        "        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, length, dim_model)\n",
        "        return tensor\n",
        "\n",
        "    def get_mask(self, x):\n",
        "        \"\"\"\n",
        "        создаем маску, которая будет иметь значение 0 для позиций, к которым не следует обращать внимание\n",
        "        в данном случае, мы создаем маску, которая будет иметь значение 0 для элементов, которые еще не были обработаны\n",
        "        (для элементов в будущем относительно текущего элемента)\n",
        "\n",
        "        :param tensor: [batch_size, head, length, dim_tensor]\n",
        "        :return: [batch_size, 1, length, length]\n",
        "        \"\"\"\n",
        "        batch_size, length = x.size(0), x.size(2)\n",
        "        mask = torch.ones((batch_size, 1, length, length), device=x.device)\n",
        "        mask = torch.tril(mask) # заполняем нижнюю треугольную часть матрицы единицами\n",
        "        return mask"
      ],
      "metadata": {
        "id": "k3UMtvTT0etS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn = MaskedSelfAttention(dim=768, num_heads=12)\n",
        "attn.load_state_dict({'c_attn.weight': state_dict['h.0.attn.c_attn.weight'],\n",
        "                      'c_attn.bias': state_dict['h.0.attn.c_attn.bias'],\n",
        "                      'c_proj.weight': state_dict['h.0.attn.c_proj.weight'],\n",
        "                      'c_proj.bias': state_dict['h.0.attn.c_proj.bias']})\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "x = torch.randn(1, 10, 768)  # [batch_size, sequence_length, dim]\n",
        "checksum = torch.sum(attn(x) * x)\n",
        "assert abs(checksum.item() - 2703.6772) < 0.1, \"layer outputs do not match reference\"\n",
        "assert not torch.allclose(attn(x[:, (1, 0), :])[:, (1, 0), :], attn(x[:, (0, 1), :])), \"masked attention must *not* be permutation-invariant\"\n",
        "print(\"It works!\")"
      ],
      "metadata": {
        "id": "a8hyV8uE0evn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d73d7816-5526-45d3-cd08-769eb9cb9b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It works!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2geyH17A0eyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now combine attention and MLP to build the full transformer layer:\n",
        "![for_transfer_seminar_nlp_ipynb.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "bSRYPYAqM_tY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerLayer(nn.Module):\n",
        "    def __init__(self, dim: int, num_heads: int):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(dim)\n",
        "        self.attn = MaskedSelfAttention(dim, num_heads) # [batch_size, length, dim_model]\n",
        "        self.ln_2 = nn.LayerNorm(dim)\n",
        "        self.mlp = FullyConnected(dim) # [batch_size, sequence_length, dim]\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.attn(self.ln_1(x))\n",
        "        out_1 = x + out\n",
        "        out = self.mlp(self.ln_2(out_1))\n",
        "        out_2 = out_1 + out # [batch_size, sequence_length, dim]\n",
        "\n",
        "        return out_2"
      ],
      "metadata": {
        "id": "PKnWfDLg0e05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = TransformerLayer(dim=768, num_heads=12)\n",
        "layer.load_state_dict({k[5:]: v for k, v in state_dict.items() if k.startswith('h.10.')})\n",
        "assert abs(torch.sum(layer(x) * x).item() - 9874.7383) < 0.1\n",
        "print(\"Good job!\")"
      ],
      "metadata": {
        "id": "ixQwjHFd0Tm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1951446b-d4fe-48a8-d493-10da8788293c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good job!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2(nn.Module):\n",
        "    def __init__(self, vocab_size: int, dim: int, num_heads: int, num_layers: int, max_position_embeddings: int = 1024):\n",
        "        super().__init__()\n",
        "        self.wte = nn.Embedding(vocab_size, dim)  # token embeddings\n",
        "        self.wpe = nn.Embedding(max_position_embeddings, dim)  # position embeddings\n",
        "        self.ln_f = nn.LayerNorm(dim)   # final layer norm - goes after all transformer layers, but before logits\n",
        "\n",
        "        self.h = nn.Sequential(*(TransformerLayer(dim, num_heads) for layer in range(num_layers)))\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        # input_ids.shape: [batch_size, sequence_length], int64 token ids\n",
        "        position_ids = torch.arange(input_ids.shape[1], device=input_ids.device).unsqueeze(0)\n",
        "\n",
        "        token_embeddings = self.wte(input_ids)\n",
        "        position_embeddings = self.wpe(position_ids)\n",
        "        full_embeddings = token_embeddings + position_embeddings\n",
        "\n",
        "        transformer_output = self.h(full_embeddings)\n",
        "        transformer_output_ln = self.ln_f(transformer_output)\n",
        "\n",
        "        # final layer: we predict logits by re-using token embeddings as linear weights\n",
        "        output_logits = transformer_output_ln @ self.wte.weight.T\n",
        "        return output_logits"
      ],
      "metadata": {
        "id": "zOXyV5_80Tpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('gpt2', add_prefix_space=True)\n",
        "model = GPT2(vocab_size=50257, dim=768, num_heads=12, num_layers=12)\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "input_ids = tokenizer(\"A quick\", return_tensors='pt')['input_ids']\n",
        "\n",
        "predicted_logits = model(input_ids)\n",
        "most_likely_token_id = predicted_logits[:, -1].argmax().item()\n",
        "\n",
        "print(\"Prediction:\", tokenizer.decode(most_likely_token_id))"
      ],
      "metadata": {
        "id": "zeavZtS_0Tr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60614c88-fc51-427b-d5b1-34a08d34d174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:  look\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The Fermi paradox \"\n",
        "tokens = tokenizer.encode(text)\n",
        "print(end=tokenizer.decode(tokens))\n",
        "line_length = len(tokenizer.decode(tokens))\n",
        "\n",
        "for i in range(500):\n",
        "    with torch.no_grad():\n",
        "        logits = model(torch.as_tensor([tokens]))\n",
        "\n",
        "    p_next = torch.softmax(logits[0, -1, :], dim=-1).data.cpu().numpy()\n",
        "    next_token_index = np.random.choice(len(p_next), p=p_next)\n",
        "\n",
        "    tokens.append(int(next_token_index))\n",
        "    print(end=tokenizer.decode(tokens[-1]))\n",
        "    line_length += len(tokenizer.decode(tokens[-1]))\n",
        "    if line_length > 120:\n",
        "      line_length = 0\n",
        "      print()"
      ],
      "metadata": {
        "id": "bVJPeT3b0Tug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "outputId": "64634a5d-fa25-4685-f6ad-4ad679064519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Fermi paradox 』 Spark measured scientistism his law and theory on eigenvalues 『evauches darkeilsraum』 『urfeüge with k\n",
            "iddenche 』 set-plan fideism 『Haapfund und Temper, Mitmitegracht』 advanced overestimation-overburst factor as starting concern\n",
            " Strength was Akihabara kaistolfungen idealism  imagined self-serving people who should be able bodied 』 Hae saan saanusen\n",
            " hanging style tesches high pointiomym achievement at \" der memezeit   μ x x Cryogenic [...] demand  ��� ��を��した 神不����で \n",
            "不���������な�����に 不��で ��イギさ��る��使�����������生������� ���いも���くて クーティー武���的����� but there they came 』\n",
            "Follow Migration\n",
            "Mobile\n",
            " CheckiYou can share a hashtag with @MigrationTwitter directly and immediately (such as #MigrationNotSingapore!).<|endoftext|>\n",
            "Still loading...\n",
            "\n",
            "A B C D E F G H I J K L M N O P Q R S T U V W X Y Z 1 record- Ratings match meaning Marin modified size\n",
            " end-match Anaheim loved Anaheim Pierogi Box score itself Total add continuation 3.3 2 ESPN 18 29 Denver vs Gulf Coast Roberts\n",
            " Warriors Green Bay Golf Vendor P Spousel Signature Pplane Set an Ammo @ 2000.00 Ultragy or 96.3a le ft roll 860joy dice485\n",
            " 31957 BAT AGAIN 33950000 100 6,178 5.37 140 3.63 3.21,,-9]: � added no stylizing usage ** long sportsman mrs & dpealles 2\n",
            " 1 Infamous Rosen https://www.youtube.com/watch?v=09-Ee6GDrzFc I want to know what he bought, if not what review he covered\n",
            " for it - two figurines in a box for $1.00 4 4 41 Times Stearns https://www.youtube.com/watch?v=5OkEdub2Whk Easy calibration\n",
            " (donation low!) and over 30 minutes of"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c0941cb880c3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mp_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-aee1f5159884>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfull_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtransformer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtransformer_output_ln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-c3586d445fd8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mout_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m \u001b[0;31m# [batch_size, sequence_length, dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d6145f72bc6c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# x.shape = [batch_size, seq_length, dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d6145f72bc6c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGeLUThatWasUsedInGPT2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.044715\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFullyConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# top-k sampling with temperature\n",
        "\n",
        "def top_k_logits(logits, k):\n",
        "    if k == 0:\n",
        "        return logits\n",
        "    values, _ = torch.topk(logits, k)\n",
        "    min_values = values[-1].expand_as(logits)\n",
        "    return torch.where(\n",
        "        logits < min_values,\n",
        "        torch.ones_like(logits) * -float('Inf'),\n",
        "        logits\n",
        "    )\n",
        "\n",
        "text = \"The Fermi paradox \"\n",
        "tokens = tokenizer.encode(text)\n",
        "print(tokenizer.decode(tokens), end=' ')\n",
        "\n",
        "temperature = 0.9\n",
        "top_k = 40\n",
        "line_length = 0\n",
        "\n",
        "for _ in range(500):\n",
        "    with torch.no_grad():\n",
        "        logits = model(torch.as_tensor([tokens]))[-1, -1, :] / temperature\n",
        "        logits = top_k_logits(logits, k=top_k)\n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "    prev = tokens[-1]\n",
        "    next_token_index = torch.multinomial(probs, num_samples=1).item()\n",
        "    tokens.append(next_token_index)\n",
        "\n",
        "    if next_token_index == prev:\n",
        "      continue  # предотвращение повторения токенов\n",
        "\n",
        "    decoded_text = tokenizer.decode([next_token_index], clean_up_tokenization_spaces=True)\n",
        "\n",
        "    line_length += len(tokenizer.decode(tokens[-1]))\n",
        "    if line_length > 40:\n",
        "      line_length = 0\n",
        "      print()\n",
        "\n",
        "    if 'n' in decoded_text or len(decoded_text) > 100:  # разделение на строки или контроль максимальной длины строки\n",
        "        print(decoded_text, end='')\n",
        "        line_length = 0\n",
        "    else:\n",
        "        print(decoded_text, end='', flush=True)\n"
      ],
      "metadata": {
        "id": "hmTYXQ4b0Tw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "955452fa-80f7-4aa3-9c7e-b71e7f384850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Fermi paradox   is a paradox that can be easily seen to apply in the universe.  A paradox is the idea that all\n",
            " reality must be a contradiction, and that every possible reality must\n",
            " contradict itself in order to be true.  It is also commonly known as the 'Fermi paradox'.  The Fermi\n",
            " Paradox is a paradox which can be easily seen to apply in the universe.  It is the paradox that has the most\n",
            " difficulty to explain in science, and which is especially hard on physicists.  And so this question has been asked and studied at universities for centuries, with different answers and different degrees of confirmation.  The Fermi paradox also holds true for\n",
            " many other complex problems which the\n",
            " Universe is incapable of experiencing.  For instance in the Big Bang, there are three possible worlds: Earth\n",
            ", Mars, and the sun, and they all exist with a single physical body (a body of matter, like\n",
            " the sun, that is similar to what the Fermi\n",
            " paradox implies).  These worlds are the planets around our own Milky Way galaxy (the farthest point from the Sun and far from the Sun-like stars).  These worlds are also\n",
            " called galaxies.  And what is happening at the outer boundaries of those worlds allows us to understand the nature of these worlds' atmospheres, as well\n",
            " as the origin of all matter in the Universe. The Fermi paradox is about how all\n",
            " possible universes are composed of the same set of atoms\n",
            " in the Universe. \n",
            "The Fermi paradox is also about how\n",
            " they relate to each other.  For instance, one universe cannot have a single chemical molecule.  In the Universe, for example, atoms (like water, oil\n",
            " and gas) are interchanged at the Big Bang. The Universe also has a number of universes in which atoms are interchanged at the Big Bang.  The fermi paradox has been discussed often in particle physics as being a case that the Universe itself can have a very special way of intermingling with each other.  The fermi paradox has\n",
            " also been proposed to explain why the Universe is a \"small\" space, where we have only a small amount of matter at the very beginning.  In some cases, a large amount of matter is intermingled with matter at the end of the Big Bang.  The Fermi paradox has been discussed regularly in quantum theory as being the \"Fermi paradox\" on a fundamental level, in the same way as \"the F"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try to write a code\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# top-k sampling with temperature\n",
        "\n",
        "def top_k_logits(logits, k):\n",
        "    if k == 0:\n",
        "        return logits\n",
        "    values, _ = torch.topk(logits, k)\n",
        "    min_values = values[-1].expand_as(logits)\n",
        "    return torch.where(\n",
        "        logits < min_values,\n",
        "        torch.ones_like(logits) * -float('Inf'),\n",
        "        logits\n",
        "    )\n",
        "\n",
        "text = 'int main() {std::cout << \"Hello, World!\"}'\n",
        "tokens = tokenizer.encode(text)\n",
        "print(tokenizer.decode(tokens), end=' ')\n",
        "\n",
        "temperature = 0.9\n",
        "top_k = 40\n",
        "line_length = 0\n",
        "\n",
        "for _ in range(50):\n",
        "    with torch.no_grad():\n",
        "        logits = model(torch.as_tensor([tokens]))[-1, -1, :] / temperature\n",
        "        logits = top_k_logits(logits, k=top_k)\n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "    prev = tokens[-1]\n",
        "    next_token_index = torch.multinomial(probs, num_samples=1).item()\n",
        "    tokens.append(next_token_index)\n",
        "\n",
        "    if next_token_index == prev:\n",
        "      continue  # предотвращение повторения токенов\n",
        "\n",
        "    decoded_text = tokenizer.decode([next_token_index], clean_up_tokenization_spaces=True)\n",
        "\n",
        "    line_length += len(tokenizer.decode(tokens[-1]))\n",
        "    if line_length > 40:\n",
        "      line_length = 0\n",
        "      print()\n",
        "\n",
        "    if '<|endoftext|>' in decoded_text:\n",
        "        break\n",
        "\n",
        "    if 'n' in decoded_text or len(decoded_text) > 100:  # разделение на строки или контроль максимальной длины строки\n",
        "        print(decoded_text, end='')\n",
        "        line_length = 0\n",
        "    else:\n",
        "        print(decoded_text, end='', flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMN3Vb4SS2mP",
        "outputId": "d2d89194-077f-4751-aec0-79dbfb9fc681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " int main() {std::cout << \"Hello, World!\"}  static void main() { std::cout << \"Hello, World!\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dDScRQY-S2ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5HqyddhfS2ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "woATReduS2xL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}