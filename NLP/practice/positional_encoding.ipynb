{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AY9XnqdQLNq4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.Tensor([[[2, 3, 4, 3, 1, 6], [1, 1, 1, 1, 1, 1], [0, -4, 18, 0, 0, 0], [5, 6, 7, 1, 4, 8]],\n",
        "                  [[1, 2, 55, 11, 34, 88], [5, 34, 13, 22, 12, 2], [0, 0, 0, 9, 98, 22], [-10, -6, 7, 23, 2, 1]]])\n",
        "a.shape # .shape -> [batch_size, seq_len, emb_size]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc0O4gD3Np5r",
        "outputId": "ac400682-3bf2-4097-8cc8-999fc8117ce7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sinusoidal PE"
      ],
      "metadata": {
        "id": "w9VGedvhLTKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Предложен в attention is all you need (2017)\n",
        "# Применяется до self_attention после входа: x = x_input + sinusoidal_pe"
      ],
      "metadata": {
        "id": "KCtYEI63LOHA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SinusoidalPositionalEncoding:\n",
        "  def __init__(self, seq_len, emb_size):\n",
        "    self.seq_len = seq_len\n",
        "    self.emb_size = emb_size\n",
        "\n",
        "  def __call__(self):\n",
        "    pos_emb = torch.zeros(self.seq_len, self.emb_size)\n",
        "    pos = torch.arange(0, self.seq_len, dtype=torch.float32).unsqueeze(-1) # [seq_len, 1]\n",
        "    denom = torch.exp(torch.arange(0, self.emb_size, 2).float() * (-math.log(10_000.0) / self.emb_size))\n",
        "    pos_emb[:, 0::2] = torch.sin(pos * denom)\n",
        "    pos_emb[:, 1::2] = torch.cos(pos * denom)\n",
        "    return pos_emb.unsqueeze(0) # [1, seq_len, emb_size]"
      ],
      "metadata": {
        "id": "YDt2wapjOg2V"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sin_pe = SinusoidalPositionalEncoding(seq_len=a.size(1),\n",
        "                                        emb_size=a.size(2))\n",
        "out = sin_pe()\n",
        "out, out.shape, a + out, (a + out).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSoAcVFALOWE",
        "outputId": "d2eb8933-f983-45b7-f935-cb5f72b18309"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
              "          [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
              "          [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
              "          [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000]]]),\n",
              " torch.Size([1, 4, 6]),\n",
              " tensor([[[ 2.0000e+00,  4.0000e+00,  4.0000e+00,  4.0000e+00,  1.0000e+00,\n",
              "            7.0000e+00],\n",
              "          [ 1.8415e+00,  1.5403e+00,  1.0464e+00,  1.9989e+00,  1.0022e+00,\n",
              "            2.0000e+00],\n",
              "          [ 9.0930e-01, -4.4161e+00,  1.8093e+01,  9.9569e-01,  4.3089e-03,\n",
              "            9.9999e-01],\n",
              "          [ 5.1411e+00,  5.0100e+00,  7.1388e+00,  1.9903e+00,  4.0065e+00,\n",
              "            9.0000e+00]],\n",
              " \n",
              "         [[ 1.0000e+00,  3.0000e+00,  5.5000e+01,  1.2000e+01,  3.4000e+01,\n",
              "            8.9000e+01],\n",
              "          [ 5.8415e+00,  3.4540e+01,  1.3046e+01,  2.2999e+01,  1.2002e+01,\n",
              "            3.0000e+00],\n",
              "          [ 9.0930e-01, -4.1615e-01,  9.2699e-02,  9.9957e+00,  9.8004e+01,\n",
              "            2.3000e+01],\n",
              "          [-9.8589e+00, -6.9900e+00,  7.1388e+00,  2.3990e+01,  2.0065e+00,\n",
              "            2.0000e+00]]]),\n",
              " torch.Size([2, 4, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relative PE"
      ],
      "metadata": {
        "id": "VniDGGw7Y8Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяется внутри self_attention при вычислении аттеншн скоров: attn_scores[i][j] += f(i - j)"
      ],
      "metadata": {
        "id": "I9x1MFH8-i0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RelativePositionalEncoding:\n",
        "  def __init__(self, seq_len, num_heads=8):\n",
        "    self.seq_len = seq_len\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "  def __call__(self):\n",
        "    max_relative_distance = 2 * self.seq_len - 1 # для seq_len=4 => [-3, -2, -1, 0, 1, 2, 3] -> 7\n",
        "    relative_positions = torch.arange(-self.seq_len + 1, self.seq_len, dtype=torch.float32).unsqueeze(-1) # для seq_len=4 => [-3, -2, -1, 0, 1, 2, 3]\n",
        "    denom = torch.exp(torch.arange(0, self.num_heads, 2).float() * (-math.log(10_000.0) / self.num_heads))\n",
        "\n",
        "    pos_emb = torch.zeros(max_relative_distance, self.num_heads)\n",
        "    pos_emb[:, 0::2] = torch.sin(relative_positions * denom)\n",
        "    pos_emb[:, 1::2] = torch.cos(relative_positions * denom)\n",
        "\n",
        "    bias = torch.zeros(self.num_heads, self.seq_len, self.seq_len) # q * k.T + relative_pe => shape\n",
        "    for i in range(self.seq_len):\n",
        "      for j in range(self.seq_len):\n",
        "        relative_pos = i - j + self.seq_len - 1\n",
        "        bias[:, i, j] = pos_emb[relative_pos]\n",
        "\n",
        "    return bias # [num_heads, seq_len, seq_len]"
      ],
      "metadata": {
        "id": "lJtr7CYhLOeW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relative_pe = RelativePositionalEncoding(seq_len=a.size(1))\n",
        "relative_bias = relative_pe()\n",
        "out = (a @ a.transpose(1, 2)).unsqueeze(1).repeat(1, 8, 1, 1) # [batch_size, 8, seq_len, seq_len] -> имитация q @ k.T\n",
        "out.shape, (out + relative_bias).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHLcaLUKY_CA",
        "outputId": "9fdac5a5-df14-4c7c-e37b-98f7b3035d94"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 8, 4, 4]), torch.Size([2, 8, 4, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rotary PE"
      ],
      "metadata": {
        "id": "mcd1AuQ-1ucK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяется внутри self_attention до dot_product q * k:\n",
        "# Q_roped = apply_rope(Q)\n",
        "# K_roped = apply_rope(K)\n",
        "# attn_scores = Q_roped @ K_roped.T"
      ],
      "metadata": {
        "id": "h4xLjcfn-2ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RotaryPositionalEmbeddings(nn.Module):\n",
        "  def __init__(self, head_dim, rope_base=10_000, max_seq_len=4096):\n",
        "    super().__init__()\n",
        "    self.head_dim = head_dim\n",
        "    self.rope_base = rope_base\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self._rope_init()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    self._rope_init()\n",
        "\n",
        "  def _rope_init(self):\n",
        "    theta = 1.0 / (self.rope_base ** torch.arange(0, self.head_dim, 2)[:(self.head_dim//2)].float() / self.head_dim)\n",
        "    self.register_buffer('theta', theta, persistent=False)\n",
        "    self.build_rope_cache(self.max_seq_len)\n",
        "\n",
        "  def build_rope_cache(self, max_seq_len=4096):\n",
        "    seq_idx = torch.arange(max_seq_len, dtype=self.rope_base.dtype, device=self.rope_base.device)\n",
        "    # outer product seq_idx и rope_theta\n",
        "    idx_theta = torch.einsum('i, j -> ij', seq_idx, self.rope_theta).float() # [max_seq_len, head_dim//2]\n",
        "    cache = torch.stack([torch.cos(idx_theta), torch.sin(idx_theta)], dim=-1) # [max_seq_len, head_dim//2, 2]\n",
        "    self.register_buffer('cache', cache, persistent=False)\n",
        "\n",
        "  def forward(self, x, input_pos=None):\n",
        "    # x.shape -> [batch_size, seq_len, num_heads, head_dim]\n",
        "    seq_len = x.size(1)\n",
        "    rope_cache = (self.cache[:seq_len] if input_pos in None else self.cache[input_pos])\n",
        "    x_shaped = x.float().reshape(*x.shape[:-1], -1, 2) # [batch_size, seq_len, num_heads, head_dim//2]\n",
        "    rope_cache = rope_cache.view(-1, x_shaped.size(1), 1, x_shaped.size(3), 2)\n",
        "\n",
        "    x_out = torch.stack(\n",
        "        [\n",
        "        x_shaped[..., 0] * rope_cache[..., 0] - x_shaped[..., 1] * rope_cache[..., 1],\n",
        "        x_shaped[..., 1] * rope_cache[..., 0] + x_shaped[..., 0] * rope_cache[..., 1]\n",
        "        ],\n",
        "        dim=-1\n",
        "    ) # [batch_size, seq_len, num_heads, head_dim//2, 2]\n",
        "    x_out = x_out.flatten(3) # [batch_size, seq_len, num_heads, head_dim]\n",
        "    return x_out"
      ],
      "metadata": {
        "id": "Mtb6K2sAY_G9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alibi (attention with linear biases)"
      ],
      "metadata": {
        "id": "1R_W6bQY9h20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяется внутри self_attention при вычислении аттеншн скоров:\n",
        "# attn_scores[i][j] += -slope * |i - j|"
      ],
      "metadata": {
        "id": "YbFSUQlDY_Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlibiPositionalBias:\n",
        "  def __init__(self, num_heads, seq_len, learnable_slopes=False):\n",
        "    self.num_heads = num_heads\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "    self.slopes = self._get_slopes(num_heads)\n",
        "    if learnable_slopes:\n",
        "      self.slopes = nn.Parameter(self.slopes, requires_grad=True)\n",
        "\n",
        "    pos = torch.arange(seq_len)\n",
        "    self.rel_dist = (pos[None, :] - pos[:, None]).abs() # [seq_len, seq_len]\n",
        "\n",
        "  def _get_slopes(self, n):\n",
        "    def get_pow2_slopes(n):\n",
        "      start = 2.0 ** (-8.0 / n)\n",
        "      return torch.Tensor([start ** i for i in range(n)])\n",
        "\n",
        "    if math.log2(n).is_integer():\n",
        "      return get_pow2_slopes(n)\n",
        "    else:\n",
        "      closest_power_of2 = 2 ** math.floor(math.log2(n))\n",
        "      base_slopes = get_pow2_slopes(closest_power_of2)\n",
        "      extra = self._get_slopes(2 * closest_power_of2)[0::2][:n-closest_power_of2]\n",
        "      return torch.cat([base_slopes, extra], dim=0)\n",
        "\n",
        "  def __call__(self):\n",
        "    # [num_heads, 1, 1] * [1, seq_len, seq_len] => [num_heads, seq_len, seq_len]\n",
        "    bias = -self.slopes[:, None, None] * self.rel_dist[None, :, :]\n",
        "    return bias # [num_heads, seq_len, seq_len]"
      ],
      "metadata": {
        "id": "N8u4gIQlY_Ly"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "num_heads = 4\n",
        "seq_len = 6\n",
        "\n",
        "attn_scores = torch.randn(batch_size, num_heads, seq_len, seq_len)\n",
        "alibi = AlibiPositionalBias(num_heads, seq_len)\n",
        "bias = alibi()  # [num_heads, seq_len, seq_len]\n",
        "\n",
        "attn_scores_with_alibi = attn_scores + bias.unsqueeze(0)  # [batch_size, num_heads, seq_len, seq_len]"
      ],
      "metadata": {
        "id": "CW-Tz9yRY_N1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CoXOdt23Y_Tn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}